{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider.data_factory import data_provider\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual, vali, test\n",
    "from torch.utils.data import Subset\n",
    "from tqdm import tqdm\n",
    "from models.PatchTST import PatchTST\n",
    "from models.GPT4TS import GPT4TS\n",
    "from models.DLinear import DLinear\n",
    "from models.TEMPO import TEMPO\n",
    "# from models.T5 import T54TS\n",
    "from models.ETSformer import ETSformer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from numpy.random import choice\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from numpy.random import choice\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init_config(config_path=None):\n",
    "    config = OmegaConf.load(config_path)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Define the configuration dictionary\n",
    "config = {\n",
    "    \"datasets\": {\n",
    "        \"Solar\": {\n",
    "            \"root_path\": \"/u/dcao1/workspace/Generative-TS-train_all/csdi_data/solar_nips/\",\n",
    "            \"data_path\": \"test/test.csv\",\n",
    "            \"data_name\": \"Solar\",\n",
    "            \"data\": \"solar\",\n",
    "            \"lradj\": \"type4\",\n",
    "            \"features\": \"M\",\n",
    "            \"target\": \"400001\",\n",
    "            \"embed\": \"timeF\",\n",
    "            \"freq\": 0,\n",
    "            \"percent\": 100\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create an OmegaConf object from the dictionary\n",
    "cfg = OmegaConf.create(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to ./configs/custom_dataset.yml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the configuration to a YAML file\n",
    "with open(\"./configs/custom_dataset.yml\", \"w\") as f:\n",
    "    OmegaConf.save(cfg, f)\n",
    "\n",
    "print(\"Configuration saved to ./configs/custom_dataset.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration written to config.yml\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"description\": \"TEMPO\",\n",
    "    \"checkpoints\": \"checkpoints/lora_revin_5domain_checkpoints_1/\",\n",
    "    \"task_name\": \"long_term_forecast\",\n",
    "    \"prompt\": 1,\n",
    "    \"num_nodes\": 1,\n",
    "    \"seq_len\": 168,\n",
    "    \"pred_len\": 30, #24\n",
    "    \"label_len\": 30,\n",
    "    \"decay_fac\": 0.5,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 256,\n",
    "    \"num_workers\": 0,\n",
    "    \"train_epochs\": 10,\n",
    "    \"lradj\": \"type3\",\n",
    "    \"patience\": 5,\n",
    "    \"gpt_layers\": 6,\n",
    "    \"is_gpt\": 1,\n",
    "    \"e_layers\": 3,\n",
    "    \"d_model\": 768,\n",
    "    \"n_heads\": 4,\n",
    "    \"d_ff\": 768,\n",
    "    \"dropout\": 0.3,\n",
    "    \"enc_in\": 7,\n",
    "    \"c_out\": 1,\n",
    "    \"patch_size\": 16,\n",
    "    \"kernel_size\": 25,\n",
    "    \"loss_func\": \"mse\",\n",
    "    \"pretrain\": 1,\n",
    "    \"freeze\": 1,\n",
    "    \"model\": \"TEMPO\",\n",
    "    \"stride\": 8,\n",
    "    \"max_len\": -1,\n",
    "    \"hid_dim\": 16,\n",
    "    \"tmax\": 20,\n",
    "    \"itr\": 3,\n",
    "    \"cos\": 1,\n",
    "    \"equal\": 1,\n",
    "    \"pool\": False,\n",
    "    \"no_stl_loss\": False,\n",
    "    \"stl_weight\": 0.001,\n",
    "    \"config_path\": \"./configs/custom_dataset.yml\",\n",
    "    \"datasets\": \"ETTm1,ETTh1,ETTm2,electricity,traffic,weather\",\n",
    "    \"target_data\": \"Solar\",\n",
    "    \"use_token\": 0,\n",
    "    \"electri_multiplier\": 1,\n",
    "    \"traffic_multiplier\": 1,\n",
    "    \"embed\": \"timeF\",\n",
    "    \"percent\": 100,\n",
    "    # \"model_id\": 'prob_TEMPO_6_prompt_learn_168_24_100_sl336_ll168_pl24_dm768_nh4_el3_gl6_df768_ebtimeF_itr0' #\"prob_TEMPO_6_prompt_learn_168_24_100_sl336_ll30_pl30_dm768_nh4_el3_gl6_df768_ebtimeF_itr0\"\n",
    "    \"model_id\": \"prob_TEMPO_6_prompt_learn_168_30_100_sl336_ll30_pl30_dm768_nh4_el3_gl6_df768_ebtimeF_itr0\" #\"prob_TEMPO_6_prompt_learn_168_24_100_sl336_ll30_pl30_dm768_nh4_el3_gl6_df768_ebtimeF_itr0\"\n",
    "}\n",
    "\n",
    "# Create an OmegaConf object from the dictionary\n",
    "cfg = OmegaConf.create(config)\n",
    "\n",
    "# Save the configuration to a YAML file\n",
    "with open(\"configs/etth2_config.yml\", \"w\") as f:\n",
    "    OmegaConf.save(cfg, f)\n",
    "\n",
    "print(\"Configuration written to config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_init_config(cfg.config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASONALITY_MAP = {\n",
    "   \"minutely\": 1440,\n",
    "   \"10_minutes\": 144,\n",
    "   \"half_hourly\": 48,\n",
    "   \"hourly\": 24,\n",
    "   \"daily\": 7,\n",
    "   \"weekly\": 1,\n",
    "   \"monthly\": 12,\n",
    "   \"quarterly\": 4,\n",
    "   \"yearly\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 308736 || all params: 82207488 || trainable%: 0.38\n"
     ]
    }
   ],
   "source": [
    "if cfg.model == 'PatchTST':\n",
    "    model = PatchTST(cfg, device)\n",
    "    model.to(device)\n",
    "elif cfg.model == 'DLinear':\n",
    "    model = DLinear(cfg, device)\n",
    "    model.to(device)\n",
    "elif cfg.model == 'TEMPO':\n",
    "    model = TEMPO(cfg, device)\n",
    "    model.to(device)\n",
    "elif cfg.model == 'T5':\n",
    "    model = T54TS(cfg, device)\n",
    "    model.to(device)\n",
    "elif 'ETSformer' in cfg.model:\n",
    "    model = ETSformer(cfg, device)\n",
    "    model.to(device)\n",
    "else:\n",
    "    model = GPT4TS(cfg, device)\n",
    "\n",
    "\n",
    "params = model.parameters()\n",
    "model_optim = torch.optim.Adam(params, lr=cfg.learning_rate)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=cfg.patience, verbose=True)\n",
    "if cfg.loss_func == 'mse':\n",
    "    criterion = nn.MSELoss()\n",
    "elif cfg.loss_func == 'smape':\n",
    "    class SMAPE(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SMAPE, self).__init__()\n",
    "        def forward(self, pred, true):\n",
    "            return torch.mean(200 * torch.abs(pred - true) / (torch.abs(pred) + torch.abs(true) + 1e-8))\n",
    "    criterion = SMAPE()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(model_optim, T_max=cfg.tmax, eta_min=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/lora_revin_5domain_checkpoints_1/prob_TEMPO_6_prompt_learn_168_30_100_sl336_ll30_pl30_dm768_nh4_el3_gl6_df768_ebtimeF_itr0/checkpoint.pth\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(cfg.checkpoints, cfg.model_id)\n",
    "best_model_path = model_path + '/checkpoint.pth'\n",
    "print(best_model_path)\n",
    "model.load_state_dict(torch.load(best_model_path,  map_location=torch.device(device)), strict=False)\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.enc_in = 137\n",
      "self.data_x = (7, 137)\n",
      "test 7\n"
     ]
    }
   ],
   "source": [
    "cfg.data = config['datasets'][cfg.target_data].data\n",
    "cfg.root_path = config['datasets'][cfg.target_data].root_path\n",
    "cfg.data_path = config['datasets'][cfg.target_data].data_path\n",
    "cfg.data_name = config['datasets'][cfg.target_data].data_name\n",
    "cfg.features = config['datasets'][cfg.target_data].features\n",
    "cfg.freq = config['datasets'][cfg.target_data].freq\n",
    "cfg.target = config['datasets'][cfg.target_data].target\n",
    "cfg.embed = config['datasets'][cfg.target_data].embed\n",
    "cfg.percent = config['datasets'][cfg.target_data].percent\n",
    "cfg.lradj = config['datasets'][cfg.target_data].lradj\n",
    "if cfg.freq == 0:\n",
    "    cfg.freq = 'h'\n",
    "cfg.seq_len = 168 + 24\n",
    "cfg.pred_len = 24 \n",
    "test_data, test_loader = data_provider(cfg, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 87.58765 ,  38.1089  ,  36.878876,  38.680717,  74.740814,\n",
       "       100.72187 ,  34.929775,  34.72166 ,  38.54339 ,  36.66024 ,\n",
       "        36.24879 ,  20.498371,  38.83451 ,  36.9731  ,  39.425587,\n",
       "        24.803717,  38.698612,  38.37145 ,  36.375454,  36.688168,\n",
       "        38.70079 ,  38.435272,  48.711697,  81.96147 ,  38.615086,\n",
       "        32.350006,  36.39808 ,  38.585712,  81.54733 ,  36.545185,\n",
       "        36.812992,  71.320625,  38.59133 ,  34.578987,  34.22856 ,\n",
       "        30.669676,  38.383503,  27.520584,  38.10523 ,  36.47746 ,\n",
       "        90.69661 ,  37.280773,  39.652153,  36.49171 ,  62.690407,\n",
       "        37.48001 ,  27.493147,  34.83882 ,  38.150475,  37.91924 ,\n",
       "        38.649918,  36.806263,  38.122124,  38.63643 ,  34.987503,\n",
       "        38.54304 ,  38.58559 ,  34.352345,  34.68059 ,  38.409283,\n",
       "        27.211773,  39.226173,  36.36521 ,  34.60476 ,  36.09768 ,\n",
       "        37.850525,  39.01769 ,  38.383133,  81.14679 ,  71.17894 ,\n",
       "        51.486794,  26.875301,  36.03495 , 124.58435 ,  38.810318,\n",
       "        38.40561 ,  39.311787,  36.106342,  39.63887 ,  36.57995 ,\n",
       "        50.45343 ,  36.00588 ,  34.795124,  27.213577,  36.606293,\n",
       "        34.531853,  38.535877,  34.78034 ,  32.464977,  34.621765,\n",
       "        26.840054,  34.80649 ,  38.626347,  34.810955,  34.71876 ,\n",
       "        36.15675 ,  36.42902 ,  34.639565,  32.20144 ,  38.515644,\n",
       "        27.46699 ,  27.443163,  36.24346 ,  36.248314,  59.74045 ,\n",
       "        61.56987 ,  34.97117 ,  38.826904,  34.4147  ,  38.68581 ,\n",
       "        37.119957,  39.049404,  20.741888,  34.095013,  37.86639 ,\n",
       "        10.052136,  38.982807,  38.13969 ,  38.320293,  26.99939 ,\n",
       "        38.607433,  95.479774,  39.43054 ,  38.42482 ,  61.470013,\n",
       "        50.568966,  19.72815 ,  36.221302,  38.41181 ,  10.090717,\n",
       "        30.760742,  36.280815,  36.722378,  38.178265,  38.410526,\n",
       "        37.416367,  49.713604], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.mean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 137, 30])\n",
      "torch.Size([35, 137, 30])\n",
      "torch.Size([35, 137, 30])\n",
      "torch.Size([35, 137, 30])\n",
      "torch.Size([35, 137, 30])\n",
      "torch.Size([35, 137, 30])\n",
      "torch.Size([35, 137, 30])\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import torch.distributions as dist\n",
    "preds = []\n",
    "trues = []\n",
    "# mases = []\n",
    "\n",
    "# Initialize accumulators for errors\n",
    "total_mae = 0\n",
    "total_mse = 0\n",
    "n_samples = 0\n",
    "itr = 0\n",
    "\n",
    "cfg.seq_len = 168\n",
    "cfg.pred_len = 24\n",
    "model.eval()\n",
    "# import pdb; pdb.set_trace()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        #enumerate(test_loader): #tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "        data = test_data[i]\n",
    "        seq_x, text_embedding, observed_mask = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        seq_x = seq_x.float().to(device)\n",
    "        batch_x = seq_x[:, :cfg.seq_len].unsqueeze(-1) # 137, 168, 1\n",
    "        batch_y = seq_x[:,cfg.seq_len:cfg.seq_len+cfg.pred_len]\n",
    "        trues.append(batch_y.cpu().numpy())\n",
    "\n",
    "                        \n",
    "        outputs, _ = model(batch_x, 0, None, None, None) #+ model(seq_seasonal, ii) + model(seq_resid, ii)\n",
    "\n",
    "        mu, sigma, nu = outputs[0], outputs[1], outputs[2]\n",
    "        # Create the Student's t-distribution with the predicted parameters\n",
    "        student_t = dist.StudentT(df=nu, loc=mu, scale=sigma)\n",
    "\n",
    "        # Generate 30 samples for each prediction\n",
    "        num_samples = 35\n",
    "        probabilistic_forecasts = student_t.rsample((num_samples,))\n",
    "\n",
    "        # The shape of probabilistic_forecasts will be (num_samples, batch_size, pred_length)\n",
    "        print(probabilistic_forecasts.shape)\n",
    "        preds.append(probabilistic_forecasts.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.81706506, -0.81706506, -0.81706506, ..., -0.81706506,\n",
       "        -0.81706506, -0.81706506],\n",
       "       [-0.72572196, -0.72572196, -0.72572196, ..., -0.72572196,\n",
       "        -0.72572196, -0.72572196],\n",
       "       [-0.71024656, -0.71024656, -0.71024656, ..., -0.71024656,\n",
       "        -0.71024656, -0.71024656],\n",
       "       ...,\n",
       "       [-0.7138923 , -0.7138923 , -0.7138923 , ..., -0.7138923 ,\n",
       "        -0.7138923 , -0.7138923 ],\n",
       "       [-0.8102401 , -0.8102401 , -0.8102401 , ..., -0.8102401 ,\n",
       "        -0.8102401 , -0.8102401 ],\n",
       "       [-0.71037203, -0.71037203, -0.71037203, ..., -0.71037203,\n",
       "        -0.71037203, -0.71037203]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trues[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.7650128 , -0.47545376, -1.760647  , ..., -1.2306131 ,\n",
       "         -0.09866357, -1.2889092 ],\n",
       "        [-0.76415837, -0.8843752 , -0.9411267 , ...,  0.17075074,\n",
       "         -0.90446854, -0.82463694],\n",
       "        [-0.51783204, -1.3422279 , -0.7180988 , ..., -1.7648932 ,\n",
       "         -0.5568201 , -0.3918625 ],\n",
       "        ...,\n",
       "        [-0.641276  , -1.2405138 , -0.5358103 , ...,  0.33910656,\n",
       "         -0.5380812 , -0.20042056],\n",
       "        [-0.8433978 , -0.01614326, -0.6952297 , ..., -0.8741203 ,\n",
       "         -0.41309783, -3.4668992 ],\n",
       "        [-0.586349  , -0.6225178 , -0.95038027, ..., -0.1887055 ,\n",
       "         -0.23850313, -0.47714406]],\n",
       "\n",
       "       [[-0.8346154 , -1.3662869 , -0.9986919 , ..., -1.3542612 ,\n",
       "          0.25708032, -0.393062  ],\n",
       "        [-0.81588143, -1.001123  , -0.68865395, ..., -1.0375907 ,\n",
       "         -0.8422663 , -0.78519213],\n",
       "        [-0.38844794, -0.06995958, -1.3511779 , ..., -1.4385002 ,\n",
       "         -0.25942   ,  0.64733624],\n",
       "        ...,\n",
       "        [-1.0257558 , -1.2554655 , -0.710295  , ..., -0.70039   ,\n",
       "         -1.0659785 ,  0.62636125],\n",
       "        [-0.972466  , -0.79365087, -1.2025787 , ..., -0.9800335 ,\n",
       "          0.36449128, -0.7893329 ],\n",
       "        [-0.79480886, -0.79786104, -0.98274565, ...,  0.22095042,\n",
       "         -0.94138557,  0.10235566]],\n",
       "\n",
       "       [[-1.0792953 ,  0.51998746, -0.9615438 , ..., -0.82207996,\n",
       "         -0.6929549 , -0.34247032],\n",
       "        [-0.6681774 , -0.7967088 , -0.7703174 , ..., -0.6196683 ,\n",
       "         -0.6561358 , -1.1333756 ],\n",
       "        [-0.8221909 , -0.70079833, -0.7735618 , ...,  0.15587991,\n",
       "         -0.5132712 ,  0.04170799],\n",
       "        ...,\n",
       "        [-0.860078  , -0.7576162 , -0.82096374, ..., -1.3730164 ,\n",
       "         -0.8211736 ,  0.03379422],\n",
       "        [-1.234059  , -0.576051  , -0.85089046, ..., -0.9984057 ,\n",
       "         -1.4668857 ,  0.6411608 ],\n",
       "        [-1.0175369 , -0.4106521 , -1.1783054 , ..., -0.5577665 ,\n",
       "          1.4425299 ,  0.14309031]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.84900355, -1.4284301 , -0.46439278, ..., -0.68228775,\n",
       "         -0.42937455, -1.794595  ],\n",
       "        [-0.64915955,  0.71345025, -0.6329416 , ..., -0.51752543,\n",
       "         -1.3032749 , -0.8572931 ],\n",
       "        [-0.51184005, -0.9584517 , -1.6137588 , ...,  0.42804384,\n",
       "         -0.82813597, -0.9770472 ],\n",
       "        ...,\n",
       "        [-1.0360388 , -0.29864717, -0.3378526 , ..., -0.68516886,\n",
       "         -0.55898464,  0.01834911],\n",
       "        [-0.6884899 , -0.9984688 , -1.171271  , ..., -1.5409265 ,\n",
       "         -0.12202251,  0.90579766],\n",
       "        [-0.8117436 , -0.29456428, -1.5520027 , ..., -1.9613442 ,\n",
       "         -0.45779485, -0.26267844]],\n",
       "\n",
       "       [[-1.2079175 , -1.0554916 , -1.067449  , ..., -1.4731919 ,\n",
       "         -1.1356938 , -0.7124495 ],\n",
       "        [-0.6636756 , -0.5875652 , -1.2519343 , ..., -0.91934407,\n",
       "         -0.9493042 , -0.73554385],\n",
       "        [-0.8174497 , -0.52002704, -1.0413833 , ..., -0.4798168 ,\n",
       "         -0.7948054 , -1.3729432 ],\n",
       "        ...,\n",
       "        [-0.01135445, -0.42078787, -0.96169406, ..., -0.34528592,\n",
       "         -1.5335872 ,  0.93067694],\n",
       "        [-5.153982  , -0.96301824, -0.995733  , ...,  0.17477763,\n",
       "         -1.5520533 , -1.5679507 ],\n",
       "        [-0.46326467, -0.99883574, -1.0823921 , ..., -0.6873267 ,\n",
       "         -0.3178895 , -0.03861773]],\n",
       "\n",
       "       [[-0.6608395 , -1.8144522 , -1.5583087 , ..., -0.37890914,\n",
       "         -0.84585893, -0.641761  ],\n",
       "        [-0.8358222 , -0.96817595, -0.6270609 , ..., -0.669211  ,\n",
       "         -0.8977132 ,  0.10227251],\n",
       "        [-0.78699523, -1.1576462 , -0.6392071 , ...,  0.16094297,\n",
       "         -0.7899612 , -0.5567271 ],\n",
       "        ...,\n",
       "        [-1.0649843 , -0.3889509 , -1.1362941 , ..., -0.62082136,\n",
       "         -1.1845757 , -0.5598643 ],\n",
       "        [-0.38784957, -0.8310594 , -1.1116428 , ..., -0.8087292 ,\n",
       "         -1.5982409 , -0.25653744],\n",
       "        [-0.8723475 , -1.4030372 , -0.329718  , ..., -0.7441488 ,\n",
       "         -1.844243  ,  0.00720578]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7, 35, 137, 30), (7, 137, 24))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(preds).shape, np.array(trues).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data = np.array(trues)\n",
    "synthetic_data = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = synthetic_data[:,:,:, :gt_data.shape[2]]\n",
    "target_mask = np.ones_like(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic_data = np.swapaxes(synthetic_data, -1, -2)\n",
    "# gt_data = np.swapaxes(gt_data, -1, -2)\n",
    "# synthetic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.imputation_metrics import mse_withmask, mae_withmask, calc_quantile_CRPS, calc_quantile_CRPS_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8426108109323602"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_quantile_CRPS_sum(torch.Tensor(gt_data),torch.Tensor(synthetic_data),torch.Tensor(target_mask),mean_scaler=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic_data = np.array(synthetic_data).reshape(synthetic_data.shape[0],-1,synthetic_data.shape[2],synthetic_data.shape[3])\n",
    "# gt_data = np.array(gt_data).reshape(gt_data.shape[0],gt_data.shape[2], -1)\n",
    "# target_mask = np.ones_like(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7, 137, 24), (7, 35, 137, 24))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unormzalized_gt_data = []\n",
    "for g in gt_data:\n",
    "    unormzalized_gt_data.append(np.transpose(np.transpose(g)*test_data.std_data+test_data.mean_data))\n",
    "unormzalized_gt_data = np.array(unormzalized_gt_data)\n",
    "unormalized_synthetic_data = []\n",
    "for i in range(len(synthetic_data)):\n",
    "    for j in range(len(synthetic_data[i])):\n",
    "        s = synthetic_data[i][j]\n",
    "        unormalized_synthetic_data.append(np.transpose(np.transpose(s)*test_data.std_data+test_data.mean_data))\n",
    "unormalized_synthetic_data = np.array(unormalized_synthetic_data).reshape(synthetic_data.shape[0],-1,synthetic_data.shape[2],synthetic_data.shape[3])\n",
    "unormzalized_gt_data.shape,unormalized_synthetic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 137, 24)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unormzalized_gt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 35, 137, 24)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unormalized_synthetic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 137, 24)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unormalized_synthetic_data = np.swapaxes(unormalized_synthetic_data, -1, -2)\n",
    "unormzalized_gt_data = np.swapaxes(unormzalized_gt_data, -1, -2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mask = np.ones_like(unormzalized_gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.571761733607242"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data),torch.Tensor(target_mask),mean_scaler=0,scaler=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.571761733607242"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data),torch.Tensor(target_mask),mean_scaler=0,scaler=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all:   CRPS_sum:\n",
      "0.571761733607242\n",
      "all: CRPS_sum:\n",
      "Mean CRPS_sum: 0.5814411431028131\n",
      "Standard Deviation CRPS_sum: 0.00242828814261758\n"
     ]
    }
   ],
   "source": [
    "print(\"all:   CRPS_sum:\")\n",
    "print(calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data),torch.Tensor(target_mask),mean_scaler=0,scaler=1))\n",
    "print(\"all: CRPS_sum:\")\n",
    "# import pdb; pdb.set_trace()\n",
    "CRPS_sum_1 = calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data[:,:10]),torch.Tensor(target_mask),mean_scaler=0,scaler=1)\n",
    "CRPS_sum_2 = calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data[:,10:20]),torch.Tensor(target_mask),mean_scaler=0,scaler=1)\n",
    "CRPS_sum_3 = calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data[:,20:30]),torch.Tensor(target_mask),mean_scaler=0,scaler=1)\n",
    "\n",
    "CRPS_sum_mean = np.mean([CRPS_sum_1, CRPS_sum_2, CRPS_sum_3])\n",
    "CRPS_sum_std = np.std([CRPS_sum_1, CRPS_sum_2, CRPS_sum_3])\n",
    "print(\"Mean CRPS_sum:\", CRPS_sum_mean)\n",
    "print(\"Standard Deviation CRPS_sum:\", CRPS_sum_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.WIS import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = np.swapaxes(unormalized_synthetic_data, -1, -2)\n",
    "\n",
    "labels = np.swapaxes(unormzalized_gt_data, -1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_q = np.quantile(synthetic_data,0.05,axis=1)\n",
    "high_q = np.quantile(synthetic_data,0.95,axis=1)\n",
    "mid_q = np.quantile(synthetic_data,0.5,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(959, 24) (959, 24) (959, 24)\n"
     ]
    }
   ],
   "source": [
    "high_q_reshape = np.reshape(high_q,newshape=(-1,high_q.shape[-1]))\n",
    "low_q_reshape = np.reshape(low_q,newshape=(-1,low_q.shape[-1]))\n",
    "gt_data_reshape = np.reshape(labels,newshape=(-1,labels.shape[-1]))\n",
    "print(high_q_reshape.shape,low_q_reshape.shape,gt_data_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05 # to be set by competition hosts\n",
    "if not(alpha > 0 and alpha <= 1):\n",
    "    raise ParticipantVisibleError(f'alpha should be (0,1]. Found {alpha}')\n",
    "\n",
    "MWIS,coverage = score(gt_data_reshape,high_q_reshape,low_q_reshape,alpha)\n",
    "\n",
    "if not(coverage >= (1-alpha)):\n",
    "    raise ParticipantVisibleError(f'Coverage was below {(1-alpha)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228.92459874821702, 20.62148070907195)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MWIS,coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
