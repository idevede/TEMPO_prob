{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider.data_factory import data_provider\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual, vali, test\n",
    "from torch.utils.data import Subset\n",
    "from tqdm import tqdm\n",
    "from models.PatchTST import PatchTST\n",
    "from models.GPT4TS import GPT4TS\n",
    "from models.DLinear import DLinear\n",
    "from models.TEMPO import TEMPO\n",
    "# from models.T5 import T54TS\n",
    "from models.ETSformer import ETSformer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from numpy.random import choice\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from numpy.random import choice\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init_config(config_path=None):\n",
    "    config = OmegaConf.load(config_path)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Define the configuration dictionary\n",
    "config = {\n",
    "    \"datasets\": {\n",
    "        \"Traffic\": {\n",
    "            \"root_path\": \"/u/dcao1/workspace/Generative-TS-train_all/csdi_data/traffic_nips/\",\n",
    "            \"data_path\": \"train\",\n",
    "            \"data_name\": \"Traffic\",\n",
    "            \"data\": \"traffic\",\n",
    "            \"lradj\": \"type4\",\n",
    "            \"features\": \"M\",\n",
    "            \"target\": \"400001\",\n",
    "            \"embed\": \"timeF\",\n",
    "            \"freq\": 0,\n",
    "            \"percent\": 100\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create an OmegaConf object from the dictionary\n",
    "cfg = OmegaConf.create(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to ./configs/custom_dataset.yml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the configuration to a YAML file\n",
    "with open(\"./configs/custom_dataset.yml\", \"w\") as f:\n",
    "    OmegaConf.save(cfg, f)\n",
    "\n",
    "print(\"Configuration saved to ./configs/custom_dataset.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration written to config.yml\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"description\": \"TEMPO\",\n",
    "    # \"checkpoints\": \"checkpoints/lora_revin_6domain_checkpoints_1/\",\n",
    "    \"checkpoints\": \"checkpoints/lora_revin_5domain_checkpoints_1/\",\n",
    "    \"task_name\": \"long_term_forecast\",\n",
    "    \"prompt\": 1,\n",
    "    \"num_nodes\": 1,\n",
    "    \"seq_len\": 168,\n",
    "    \"pred_len\": 30,\n",
    "    \"label_len\": 30,\n",
    "    \"decay_fac\": 0.5,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 256,\n",
    "    \"num_workers\": 0,\n",
    "    \"train_epochs\": 10,\n",
    "    \"lradj\": \"type3\",\n",
    "    \"patience\": 5,\n",
    "    \"gpt_layers\": 6,\n",
    "    \"is_gpt\": 1,\n",
    "    \"e_layers\": 3,\n",
    "    \"d_model\": 768,\n",
    "    \"n_heads\": 4,\n",
    "    \"d_ff\": 768,\n",
    "    \"dropout\": 0.3,\n",
    "    \"enc_in\": 7,\n",
    "    \"c_out\": 1,\n",
    "    \"patch_size\": 16,\n",
    "    \"kernel_size\": 25,\n",
    "    \"loss_func\": \"mse\",\n",
    "    \"pretrain\": 1,\n",
    "    \"freeze\": 1,\n",
    "    \"model\": \"TEMPO\",\n",
    "    \"stride\": 8,\n",
    "    \"max_len\": -1,\n",
    "    \"hid_dim\": 16,\n",
    "    \"tmax\": 20,\n",
    "    \"itr\": 3,\n",
    "    \"cos\": 1,\n",
    "    \"equal\": 1,\n",
    "    \"pool\": False,\n",
    "    \"no_stl_loss\": False,\n",
    "    \"stl_weight\": 0.001,\n",
    "    \"config_path\": \"./configs/custom_dataset.yml\",\n",
    "    \"datasets\": \"ETTm1,ETTh1,ETTm2,electricity,traffic,weather\",\n",
    "    \"target_data\": \"Traffic\",\n",
    "    \"use_token\": 0,\n",
    "    \"electri_multiplier\": 1,\n",
    "    \"traffic_multiplier\": 1,\n",
    "    \"embed\": \"timeF\",\n",
    "    \"percent\": 100,\n",
    "    # \"model_id\": 'prob_TEMPO_6_prompt_learn_168_24_100_sl336_ll168_pl24_dm768_nh4_el3_gl6_df768_ebtimeF_itr0' #\"prob_TEMPO_6_prompt_learn_168_24_100_sl336_ll30_pl30_dm768_nh4_el3_gl6_df768_ebtimeF_itr0\"\n",
    "     \"model_id\": \"prob_TEMPO_6_prompt_learn_168_30_100_sl336_ll30_pl30_dm768_nh4_el3_gl6_df768_ebtimeF_itr0\"\n",
    "}\n",
    "\n",
    "# Create an OmegaConf object from the dictionary\n",
    "cfg = OmegaConf.create(config)\n",
    "\n",
    "# Save the configuration to a YAML file\n",
    "with open(\"configs/etth2_config.yml\", \"w\") as f:\n",
    "    OmegaConf.save(cfg, f)\n",
    "\n",
    "print(\"Configuration written to config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_init_config(cfg.config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASONALITY_MAP = {\n",
    "   \"minutely\": 1440,\n",
    "   \"10_minutes\": 144,\n",
    "   \"half_hourly\": 48,\n",
    "   \"hourly\": 24,\n",
    "   \"daily\": 7,\n",
    "   \"weekly\": 1,\n",
    "   \"monthly\": 12,\n",
    "   \"quarterly\": 4,\n",
    "   \"yearly\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 308736 || all params: 82207488 || trainable%: 0.38\n"
     ]
    }
   ],
   "source": [
    "if cfg.model == 'PatchTST':\n",
    "    model = PatchTST(cfg, device)\n",
    "    model.to(device)\n",
    "elif cfg.model == 'DLinear':\n",
    "    model = DLinear(cfg, device)\n",
    "    model.to(device)\n",
    "elif cfg.model == 'TEMPO':\n",
    "    model = TEMPO(cfg, device)\n",
    "    model.to(device)\n",
    "elif cfg.model == 'T5':\n",
    "    model = T54TS(cfg, device)\n",
    "    model.to(device)\n",
    "elif 'ETSformer' in cfg.model:\n",
    "    model = ETSformer(cfg, device)\n",
    "    model.to(device)\n",
    "else:\n",
    "    model = GPT4TS(cfg, device)\n",
    "\n",
    "\n",
    "params = model.parameters()\n",
    "model_optim = torch.optim.Adam(params, lr=cfg.learning_rate)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=cfg.patience, verbose=True)\n",
    "if cfg.loss_func == 'mse':\n",
    "    criterion = nn.MSELoss()\n",
    "elif cfg.loss_func == 'smape':\n",
    "    class SMAPE(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SMAPE, self).__init__()\n",
    "        def forward(self, pred, true):\n",
    "            return torch.mean(200 * torch.abs(pred - true) / (torch.abs(pred) + torch.abs(true) + 1e-8))\n",
    "    criterion = SMAPE()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(model_optim, T_max=cfg.tmax, eta_min=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/lora_revin_5domain_checkpoints_1/prob_TEMPO_6_prompt_learn_168_30_100_sl336_ll30_pl30_dm768_nh4_el3_gl6_df768_ebtimeF_itr0/checkpoint.pth\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(cfg.checkpoints, cfg.model_id)\n",
    "best_model_path = model_path + '/checkpoint.pth'\n",
    "print(best_model_path)\n",
    "model.load_state_dict(torch.load(best_model_path,  map_location=torch.device(device)), strict=False)\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.enc_in = 963\n",
      "self.data_x = (7, 963)\n",
      "test 7\n"
     ]
    }
   ],
   "source": [
    "cfg.data = config['datasets'][cfg.target_data].data\n",
    "cfg.root_path = config['datasets'][cfg.target_data].root_path\n",
    "cfg.data_path = config['datasets'][cfg.target_data].data_path\n",
    "cfg.data_name = config['datasets'][cfg.target_data].data_name\n",
    "cfg.features = config['datasets'][cfg.target_data].features\n",
    "cfg.freq = config['datasets'][cfg.target_data].freq\n",
    "cfg.target = config['datasets'][cfg.target_data].target\n",
    "cfg.embed = config['datasets'][cfg.target_data].embed\n",
    "cfg.percent = config['datasets'][cfg.target_data].percent\n",
    "cfg.lradj = config['datasets'][cfg.target_data].lradj\n",
    "if cfg.freq == 0:\n",
    "    cfg.freq = 'h'\n",
    "cfg.seq_len = 168 + 24\n",
    "cfg.pred_len = 24 \n",
    "test_data, test_loader = data_provider(cfg, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.mean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 963, 30])\n",
      "torch.Size([35, 963, 30])\n",
      "torch.Size([35, 963, 30])\n",
      "torch.Size([35, 963, 30])\n",
      "torch.Size([35, 963, 30])\n",
      "torch.Size([35, 963, 30])\n",
      "torch.Size([35, 963, 30])\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import torch.distributions as dist\n",
    "preds = []\n",
    "trues = []\n",
    "history = []\n",
    "# mases = []\n",
    "\n",
    "# Initialize accumulators for errors\n",
    "total_mae = 0\n",
    "total_mse = 0\n",
    "n_samples = 0\n",
    "itr = 0\n",
    "\n",
    "cfg.seq_len = 168\n",
    "cfg.pred_len = 24\n",
    "model.eval()\n",
    "# import pdb; pdb.set_trace()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        #enumerate(test_loader): #tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "        data = test_data[i]\n",
    "        seq_x, text_embedding, observed_mask = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        seq_x = seq_x.float().to(device)\n",
    "        batch_x = seq_x[:, :cfg.seq_len].unsqueeze(-1) # 137, 168, 1\n",
    "        batch_y = seq_x[:,cfg.seq_len:cfg.seq_len+cfg.pred_len]\n",
    "        trues.append(batch_y.cpu().numpy())\n",
    "        history.append(batch_x.cpu().numpy())\n",
    "                        \n",
    "        outputs, _ = model(batch_x, 0, None, None, None) #+ model(seq_seasonal, ii) + model(seq_resid, ii)\n",
    "\n",
    "        mu, sigma, nu = outputs[0], outputs[1], outputs[2]\n",
    "        # Create the Student's t-distribution with the predicted parameters\n",
    "        student_t = dist.StudentT(df=nu, loc=mu, scale=sigma)\n",
    "\n",
    "        # Generate 30 samples for each prediction\n",
    "        num_samples = 35\n",
    "        probabilistic_forecasts = student_t.rsample((num_samples,))\n",
    "\n",
    "        # The shape of probabilistic_forecasts will be (num_samples, batch_size, pred_length)\n",
    "        print(probabilistic_forecasts.shape)\n",
    "        preds.append(probabilistic_forecasts.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03081667, 0.02231667, 0.01846667, ..., 0.02955   , 0.02948333,\n",
       "        0.02785   ],\n",
       "       [0.12431667, 0.12183333, 0.11065   , ..., 0.11313333, 0.11663333,\n",
       "        0.11951666],\n",
       "       [0.06731667, 0.05773333, 0.05038333, ..., 0.06418333, 0.06238334,\n",
       "        0.0611    ],\n",
       "       ...,\n",
       "       [0.05115   , 0.05063333, 0.04966667, ..., 0.05776667, 0.0551    ,\n",
       "        0.05406667],\n",
       "       [0.0856    , 0.07065   , 0.05335   , ..., 0.07421666, 0.07233334,\n",
       "        0.07168333],\n",
       "       [0.1395    , 0.0727    , 0.06136667, ..., 0.06471667, 0.08513334,\n",
       "        0.0609    ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trues[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.24144331e-02,  6.81488514e-02,  2.82850452e-02, ...,\n",
       "          2.01824252e-02, -3.94613743e-02,  8.15666094e-03],\n",
       "        [ 9.81072262e-02,  9.96413007e-02,  8.41377825e-02, ...,\n",
       "          1.40915245e-01,  7.33797550e-02,  4.46842641e-01],\n",
       "        [ 5.91544844e-02,  6.04421571e-02,  7.24687278e-02, ...,\n",
       "          3.56234908e-02, -4.55199629e-02, -1.52937323e-02],\n",
       "        ...,\n",
       "        [ 2.98822075e-02,  4.35462743e-02,  4.07800041e-02, ...,\n",
       "         -7.40120709e-02,  1.99849471e-01,  1.12962112e-01],\n",
       "        [ 7.85163939e-02,  1.25706121e-02, -5.87195903e-03, ...,\n",
       "          1.45974725e-01,  2.58007556e-01,  7.21831024e-02],\n",
       "        [ 1.45941585e-01,  1.60609275e-01,  9.61162150e-02, ...,\n",
       "          1.06624857e-01,  5.00327162e-03,  3.87874097e-02]],\n",
       "\n",
       "       [[ 8.28624703e-03,  8.74084793e-03,  2.00791787e-02, ...,\n",
       "          2.80775093e-02, -6.82478920e-02, -3.59249301e-04],\n",
       "        [ 1.20261207e-01,  1.09147258e-01,  8.88639241e-02, ...,\n",
       "          1.12656891e-01,  6.91867322e-02,  1.09657705e-01],\n",
       "        [ 8.48293677e-02,  3.24228108e-02,  1.09435044e-01, ...,\n",
       "          1.00216553e-01,  1.05190694e-01,  7.19835833e-02],\n",
       "        ...,\n",
       "        [ 5.95954433e-02,  3.13401483e-02,  1.71551898e-01, ...,\n",
       "         -2.87129097e-02,  1.92036644e-01,  6.98515624e-02],\n",
       "        [ 7.70247281e-02,  7.35895932e-02, -2.99010873e-02, ...,\n",
       "          1.01171538e-01,  1.19173415e-02,  1.49921685e-01],\n",
       "        [ 1.37529641e-01,  7.71212280e-02,  6.90044239e-02, ...,\n",
       "          1.17373422e-01,  1.05332047e-01,  1.33490562e-01]],\n",
       "\n",
       "       [[ 1.48525862e-02,  1.82173327e-02,  5.61631210e-02, ...,\n",
       "         -4.01618630e-01, -2.60106642e-02,  4.16505858e-02],\n",
       "        [ 1.29492402e-01,  1.29306123e-01,  1.42133027e-01, ...,\n",
       "          5.79616427e-02,  8.70527178e-02,  5.00889048e-02],\n",
       "        [ 6.28145337e-02,  6.59998655e-02,  6.21007942e-02, ...,\n",
       "         -1.58937305e-01, -2.15675607e-02,  9.66962725e-02],\n",
       "        ...,\n",
       "        [ 2.78984755e-03,  3.95484604e-02,  5.02248704e-02, ...,\n",
       "          6.78350180e-02, -2.42071986e-01,  1.13911092e-01],\n",
       "        [ 7.36904442e-02,  8.68574008e-02,  6.97896332e-02, ...,\n",
       "          8.59087259e-02,  7.45869353e-02,  5.28435893e-02],\n",
       "        [ 1.12381525e-01, -8.48254710e-02,  6.11563250e-02, ...,\n",
       "          1.17642149e-01, -1.05825797e-01,  8.47658366e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.21804418e-02,  4.57791537e-02,  6.84744306e-03, ...,\n",
       "          1.23015255e-01, -1.22009665e-02,  3.21787223e-02],\n",
       "        [ 1.42759949e-01,  1.25275716e-01,  1.09196246e-01, ...,\n",
       "          1.72755629e-01,  1.55098051e-01,  7.00085908e-02],\n",
       "        [ 7.61384666e-02,  2.07909383e-02,  8.24062601e-02, ...,\n",
       "          2.61174887e-02,  9.53086615e-02,  3.05184983e-02],\n",
       "        ...,\n",
       "        [ 1.47256628e-03, -5.80002926e-02,  9.39258188e-02, ...,\n",
       "          1.58911645e-01,  3.47899124e-02,  2.20937543e-02],\n",
       "        [ 7.73400143e-02,  6.13119826e-02,  5.93620688e-02, ...,\n",
       "          5.19420803e-02,  1.11412816e-02,  9.87778753e-02],\n",
       "        [ 1.37283295e-01,  7.50004202e-02,  7.41341338e-02, ...,\n",
       "          4.73637134e-02,  1.06352061e-01,  6.72117099e-02]],\n",
       "\n",
       "       [[-4.81054187e-04,  5.79593703e-02,  3.51958200e-02, ...,\n",
       "         -4.63541374e-02,  5.69259077e-02,  4.21445630e-02],\n",
       "        [ 1.14662021e-01,  1.21027209e-01,  9.02480632e-02, ...,\n",
       "          2.91182637e-01,  1.22134306e-01,  3.87558192e-02],\n",
       "        [ 3.66680399e-02,  6.53419271e-02,  3.19209397e-02, ...,\n",
       "         -1.43165380e-01,  1.65198632e-02,  7.44372234e-03],\n",
       "        ...,\n",
       "        [ 6.10424913e-02,  1.87176745e-02,  6.71939850e-02, ...,\n",
       "         -5.79724647e-02,  3.80090401e-02,  8.81873071e-02],\n",
       "        [ 1.10735454e-01,  8.27894732e-02,  6.61255717e-02, ...,\n",
       "          1.01583086e-01,  1.07326686e-01,  1.11591175e-01],\n",
       "        [ 1.46781176e-01,  2.77350396e-01,  4.50994596e-02, ...,\n",
       "          2.80193865e-01, -1.74333870e-01, -3.47892754e-04]],\n",
       "\n",
       "       [[ 1.40512977e-02,  4.62002866e-02,  2.65454613e-02, ...,\n",
       "          1.43618677e-02,  6.99135959e-02,  7.08887130e-02],\n",
       "        [ 9.03365910e-02,  1.07906766e-01,  2.29963571e-01, ...,\n",
       "          2.01239198e-01,  9.16006714e-02,  6.00550175e-02],\n",
       "        [ 5.50628155e-02,  5.31845167e-02,  5.99314049e-02, ...,\n",
       "          1.15998328e-01, -3.91682535e-02,  1.97639186e-02],\n",
       "        ...,\n",
       "        [ 3.21840905e-02,  1.00436591e-01,  6.88451827e-02, ...,\n",
       "         -9.82772559e-02,  4.52709831e-02, -4.47877556e-01],\n",
       "        [ 8.86621699e-02,  8.77451673e-02,  1.23641871e-01, ...,\n",
       "          4.02718671e-02,  3.27603966e-02, -3.87414917e-02],\n",
       "        [ 1.43377155e-01,  7.82241672e-02,  6.23570904e-02, ...,\n",
       "         -2.47786716e-02, -8.40325095e-03,  4.06393111e-02]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7, 35, 963, 30), (7, 963, 24))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(preds).shape, np.array(trues).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data = np.array(trues)\n",
    "synthetic_data = np.array(preds)\n",
    "history_data = np.array(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = synthetic_data[:,:,:, :gt_data.shape[2]]\n",
    "target_mask = np.ones_like(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic_data = np.swapaxes(synthetic_data, -1, -2)\n",
    "# gt_data = np.swapaxes(gt_data, -1, -2)\n",
    "# synthetic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.imputation_metrics import mse_withmask, mae_withmask, calc_quantile_CRPS, calc_quantile_CRPS_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14691095603139778"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_quantile_CRPS_sum(torch.Tensor(gt_data),torch.Tensor(synthetic_data),torch.Tensor(target_mask),mean_scaler=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic_data = np.array(synthetic_data).reshape(synthetic_data.shape[0],-1,synthetic_data.shape[2],synthetic_data.shape[3])\n",
    "# gt_data = np.array(gt_data).reshape(gt_data.shape[0],gt_data.shape[2], -1)\n",
    "# target_mask = np.ones_like(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "unormzalized_his_data = []\n",
    "for g in history_data:\n",
    "    unormzalized_his_data.append(np.transpose(np.transpose(g)*test_data.std_data+test_data.mean_data))\n",
    "unormzalized_his_data = np.array(unormzalized_his_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7, 963, 24), (7, 35, 963, 24))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unormzalized_gt_data = []\n",
    "for g in gt_data:\n",
    "    unormzalized_gt_data.append(np.transpose(np.transpose(g)*test_data.std_data+test_data.mean_data))\n",
    "unormzalized_gt_data = np.array(unormzalized_gt_data)\n",
    "unormalized_synthetic_data = []\n",
    "for i in range(len(synthetic_data)):\n",
    "    for j in range(len(synthetic_data[i])):\n",
    "        s = synthetic_data[i][j]\n",
    "        unormalized_synthetic_data.append(np.transpose(np.transpose(s)*test_data.std_data+test_data.mean_data))\n",
    "unormalized_synthetic_data = np.array(unormalized_synthetic_data).reshape(synthetic_data.shape[0],-1,synthetic_data.shape[2],synthetic_data.shape[3])\n",
    "unormzalized_gt_data.shape,unormalized_synthetic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 963, 24)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unormzalized_gt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 35, 963, 24)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unormalized_synthetic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 963, 24)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "unormalized_synthetic_data = np.swapaxes(unormalized_synthetic_data, -1, -2)\n",
    "unormzalized_gt_data = np.swapaxes(unormzalized_gt_data, -1, -2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mask = np.ones_like(unormzalized_gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03227819580780832"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data),torch.Tensor(target_mask),mean_scaler=0,scaler=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03227819580780832"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data),torch.Tensor(target_mask),mean_scaler=0,scaler=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all:   CRPS_sum:\n",
      "0.024586759115520277\n",
      "all: CRPS_sum:\n",
      "Mean CRPS_sum: 0.025835803203415452\n",
      "Standard Deviation CRPS_sum: 0.00038745621392132987\n"
     ]
    }
   ],
   "source": [
    "print(\"all:   CRPS_sum:\")\n",
    "print(calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data),torch.Tensor(target_mask),mean_scaler=0,scaler=1))\n",
    "print(\"all: CRPS_sum:\")\n",
    "# import pdb; pdb.set_trace()\n",
    "CRPS_sum_1 = calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data[:,:10]),torch.Tensor(target_mask),mean_scaler=0,scaler=1)\n",
    "CRPS_sum_2 = calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data[:,10:20]),torch.Tensor(target_mask),mean_scaler=0,scaler=1)\n",
    "CRPS_sum_3 = calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data[:,20:30]),torch.Tensor(target_mask),mean_scaler=0,scaler=1)\n",
    "\n",
    "CRPS_sum_mean = np.mean([CRPS_sum_1, CRPS_sum_2, CRPS_sum_3])\n",
    "CRPS_sum_std = np.std([CRPS_sum_1, CRPS_sum_2, CRPS_sum_3])\n",
    "print(\"Mean CRPS_sum:\", CRPS_sum_mean)\n",
    "print(\"Standard Deviation CRPS_sum:\", CRPS_sum_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_q = np.quantile(synthetic_data,0.05,axis=1)\n",
    "high_q = np.quantile(synthetic_data,0.95,axis=1)\n",
    "mid_q = np.quantile(synthetic_data,0.5,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7, 963, 168, 1), (7, 963, 24))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_data.shape, gt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 963, 192)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_data = np.concatenate([history_data.squeeze(), gt_data], axis=2)\n",
    "traj_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (7, 963, 24)\n",
      "1 (7, 963, 24)\n",
      "2 (7, 963, 24)\n",
      "3 (7, 963, 24)\n",
      "4 (7, 963, 24)\n",
      "5 (7, 963, 24)\n",
      "6 (7, 963, 24)\n",
      "7 (7, 963, 24)\n",
      "8 (7, 963, 24)\n",
      "9 (7, 963, 24)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "i = 0\n",
    "#3000\n",
    "seq_len = 192\n",
    "feat_dim = synthetic_data.shape[2]\n",
    "feat_dim = 10\n",
    "fig, axes = plt.subplots(nrows=feat_dim, ncols=1, figsize=(10, 20))\n",
    "for feat_idx in range(feat_dim):\n",
    "    # df_x = pd.DataFrame({\"x\": np.arange(0, seq_len), \"val\": gt_data[i, feat_idx, :],\n",
    "    #                      \"y\": (1-target_mask)[i, feat_idx, :]})\n",
    "    # df_x = df_x[df_x.y!=0]\n",
    "    print(feat_idx, low_q.shape)\n",
    "    df_o = pd.DataFrame({\"x\": np.arange(0, seq_len), \"val\": traj_data[i, feat_idx, :]})\n",
    "                        # \"y\": target_mask[i, feat_idx, :]})\n",
    "    # df_o = df_o[df_o.y!=0]\n",
    "    axes[feat_idx].plot(df_o.x, df_o.val, color='b',  linestyle='solid', label='label')\n",
    "    # axes[feat_idx].plot(df_x.x, df_x.val, color='r', marker='x', linestyle='None')\n",
    "    axes[feat_idx].plot(range(seq_len-24, seq_len), mid_q[i, feat_idx, -24:], color='g', linestyle='solid', label='Diffusion-TS')\n",
    "    axes[feat_idx].fill_between(range(seq_len-24, seq_len), low_q[i, feat_idx,-24:],high_q[i,feat_idx, -24:], color='g', alpha = 0.3)\n",
    "    plt.setp(axes[feat_idx], ylabel='value')\n",
    "    if feat_idx == feat_dim-1:\n",
    "        plt.setp(axes[-1], xlabel='time')\n",
    "    # plt.show()\n",
    "    # axes[feat_idx].set_ylim(-3, 3)\n",
    "plt.legend()\n",
    "plt.savefig('traffic_1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.WIS import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = np.swapaxes(unormalized_synthetic_data, -1, -2)\n",
    "\n",
    "labels = np.swapaxes(unormzalized_gt_data, -1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_q = np.quantile(synthetic_data,0.05,axis=1)\n",
    "high_q = np.quantile(synthetic_data,0.95,axis=1)\n",
    "mid_q = np.quantile(synthetic_data,0.5,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6741, 24) (6741, 24) (6741, 24)\n"
     ]
    }
   ],
   "source": [
    "high_q_reshape = np.reshape(high_q,newshape=(-1,high_q.shape[-1]))\n",
    "low_q_reshape = np.reshape(low_q,newshape=(-1,low_q.shape[-1]))\n",
    "gt_data_reshape = np.reshape(labels,newshape=(-1,labels.shape[-1]))\n",
    "print(high_q_reshape.shape,low_q_reshape.shape,gt_data_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05 # to be set by competition hosts\n",
    "if not(alpha > 0 and alpha <= 1):\n",
    "    raise ParticipantVisibleError(f'alpha should be (0,1]. Found {alpha}')\n",
    "\n",
    "MWIS,coverage = score(gt_data_reshape,high_q_reshape,low_q_reshape,alpha)\n",
    "\n",
    "if not(coverage >= (1-alpha)):\n",
    "    raise ParticipantVisibleError(f'Coverage was below {(1-alpha)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2063269790973157, 23.679424417742176)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MWIS,coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
