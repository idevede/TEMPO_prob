{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider.data_factory import data_provider\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual, vali, test\n",
    "from torch.utils.data import Subset\n",
    "from tqdm import tqdm\n",
    "from models.PatchTST import PatchTST\n",
    "from models.GPT4TS import GPT4TS\n",
    "from models.DLinear import DLinear\n",
    "from models.TEMPO import TEMPO\n",
    "# from models.T5 import T54TS\n",
    "from models.ETSformer import ETSformer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from numpy.random import choice\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from numpy.random import choice\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init_config(config_path=None):\n",
    "    config = OmegaConf.load(config_path)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Define the configuration dictionary\n",
    "config = {\n",
    "    \"datasets\": {\n",
    "        \"Solar\": {\n",
    "            \"root_path\": \"/u/dcao1/workspace/Generative-TS-train_all/csdi_data/solar_nips/\",\n",
    "            \"data_path\": \"test/test.csv\",\n",
    "            \"data_name\": \"Solar\",\n",
    "            \"data\": \"solar\",\n",
    "            \"lradj\": \"type4\",\n",
    "            \"features\": \"M\",\n",
    "            \"target\": \"400001\",\n",
    "            \"embed\": \"timeF\",\n",
    "            \"freq\": 0,\n",
    "            \"percent\": 100\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create an OmegaConf object from the dictionary\n",
    "cfg = OmegaConf.create(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to ./configs/custom_dataset.yml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the configuration to a YAML file\n",
    "with open(\"./configs/custom_dataset.yml\", \"w\") as f:\n",
    "    OmegaConf.save(cfg, f)\n",
    "\n",
    "print(\"Configuration saved to ./configs/custom_dataset.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration written to config.yml\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"description\": \"TEMPO\",\n",
    "    \"checkpoints\": \"checkpoints/lora_revin_6domain_checkpoints_1/\",\n",
    "    \"task_name\": \"long_term_forecast\",\n",
    "    \"prompt\": 1,\n",
    "    \"num_nodes\": 1,\n",
    "    \"seq_len\": 168,\n",
    "    \"pred_len\": 30,\n",
    "    \"label_len\": 30,\n",
    "    \"decay_fac\": 0.5,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 256,\n",
    "    \"num_workers\": 0,\n",
    "    \"train_epochs\": 10,\n",
    "    \"lradj\": \"type3\",\n",
    "    \"patience\": 5,\n",
    "    \"gpt_layers\": 6,\n",
    "    \"is_gpt\": 1,\n",
    "    \"e_layers\": 3,\n",
    "    \"d_model\": 768,\n",
    "    \"n_heads\": 4,\n",
    "    \"d_ff\": 768,\n",
    "    \"dropout\": 0.3,\n",
    "    \"enc_in\": 7,\n",
    "    \"c_out\": 1,\n",
    "    \"patch_size\": 16,\n",
    "    \"kernel_size\": 25,\n",
    "    \"loss_func\": \"mse\",\n",
    "    \"pretrain\": 1,\n",
    "    \"freeze\": 1,\n",
    "    \"model\": \"TEMPO\",\n",
    "    \"stride\": 8,\n",
    "    \"max_len\": -1,\n",
    "    \"hid_dim\": 16,\n",
    "    \"tmax\": 20,\n",
    "    \"itr\": 3,\n",
    "    \"cos\": 1,\n",
    "    \"equal\": 1,\n",
    "    \"pool\": False,\n",
    "    \"no_stl_loss\": False,\n",
    "    \"stl_weight\": 0.001,\n",
    "    \"config_path\": \"./configs/custom_dataset.yml\",\n",
    "    \"datasets\": \"ETTm1,ETTh1,ETTm2,electricity,traffic,weather\",\n",
    "    \"target_data\": \"Solar\",\n",
    "    \"use_token\": 0,\n",
    "    \"electri_multiplier\": 1,\n",
    "    \"traffic_multiplier\": 1,\n",
    "    \"embed\": \"timeF\",\n",
    "    \"percent\": 100,\n",
    "    \"model_id\": \"prob_TEMPO_6_prompt_learn_168_30_100_sl336_ll30_pl30_dm768_nh4_el3_gl6_df768_ebtimeF_itr0\"\n",
    "}\n",
    "\n",
    "# Create an OmegaConf object from the dictionary\n",
    "cfg = OmegaConf.create(config)\n",
    "\n",
    "# Save the configuration to a YAML file\n",
    "with open(\"configs/etth2_config.yml\", \"w\") as f:\n",
    "    OmegaConf.save(cfg, f)\n",
    "\n",
    "print(\"Configuration written to config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_init_config(cfg.config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASONALITY_MAP = {\n",
    "   \"minutely\": 1440,\n",
    "   \"10_minutes\": 144,\n",
    "   \"half_hourly\": 48,\n",
    "   \"hourly\": 24,\n",
    "   \"daily\": 7,\n",
    "   \"weekly\": 1,\n",
    "   \"monthly\": 12,\n",
    "   \"quarterly\": 4,\n",
    "   \"yearly\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 308736 || all params: 82207488 || trainable%: 0.38\n"
     ]
    }
   ],
   "source": [
    "if cfg.model == 'PatchTST':\n",
    "    model = PatchTST(cfg, device)\n",
    "    model.to(device)\n",
    "elif cfg.model == 'DLinear':\n",
    "    model = DLinear(cfg, device)\n",
    "    model.to(device)\n",
    "elif cfg.model == 'TEMPO':\n",
    "    model = TEMPO(cfg, device)\n",
    "    model.to(device)\n",
    "elif cfg.model == 'T5':\n",
    "    model = T54TS(cfg, device)\n",
    "    model.to(device)\n",
    "elif 'ETSformer' in cfg.model:\n",
    "    model = ETSformer(cfg, device)\n",
    "    model.to(device)\n",
    "else:\n",
    "    model = GPT4TS(cfg, device)\n",
    "\n",
    "\n",
    "params = model.parameters()\n",
    "model_optim = torch.optim.Adam(params, lr=cfg.learning_rate)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=cfg.patience, verbose=True)\n",
    "if cfg.loss_func == 'mse':\n",
    "    criterion = nn.MSELoss()\n",
    "elif cfg.loss_func == 'smape':\n",
    "    class SMAPE(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SMAPE, self).__init__()\n",
    "        def forward(self, pred, true):\n",
    "            return torch.mean(200 * torch.abs(pred - true) / (torch.abs(pred) + torch.abs(true) + 1e-8))\n",
    "    criterion = SMAPE()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(model_optim, T_max=cfg.tmax, eta_min=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/lora_revin_6domain_checkpoints_1/prob_TEMPO_6_prompt_learn_168_30_100_sl336_ll30_pl30_dm768_nh4_el3_gl6_df768_ebtimeF_itr0/checkpoint.pth\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(cfg.checkpoints, cfg.model_id)\n",
    "best_model_path = model_path + '/checkpoint.pth'\n",
    "print(best_model_path)\n",
    "model.load_state_dict(torch.load(best_model_path,  map_location=torch.device(device)), strict=False)\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.enc_in = 137\n",
      "self.data_x = (7, 137)\n",
      "test 7\n"
     ]
    }
   ],
   "source": [
    "cfg.data = config['datasets'][cfg.target_data].data\n",
    "cfg.root_path = config['datasets'][cfg.target_data].root_path\n",
    "cfg.data_path = config['datasets'][cfg.target_data].data_path\n",
    "cfg.data_name = config['datasets'][cfg.target_data].data_name\n",
    "cfg.features = config['datasets'][cfg.target_data].features\n",
    "cfg.freq = config['datasets'][cfg.target_data].freq\n",
    "cfg.target = config['datasets'][cfg.target_data].target\n",
    "cfg.embed = config['datasets'][cfg.target_data].embed\n",
    "cfg.percent = config['datasets'][cfg.target_data].percent\n",
    "cfg.lradj = config['datasets'][cfg.target_data].lradj\n",
    "if cfg.freq == 0:\n",
    "    cfg.freq = 'h'\n",
    "cfg.seq_len = 168 + 24\n",
    "cfg.pred_len = 24 \n",
    "test_data, test_loader = data_provider(cfg, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 87.58765 ,  38.1089  ,  36.878876,  38.680717,  74.740814,\n",
       "       100.72187 ,  34.929775,  34.72166 ,  38.54339 ,  36.66024 ,\n",
       "        36.24879 ,  20.498371,  38.83451 ,  36.9731  ,  39.425587,\n",
       "        24.803717,  38.698612,  38.37145 ,  36.375454,  36.688168,\n",
       "        38.70079 ,  38.435272,  48.711697,  81.96147 ,  38.615086,\n",
       "        32.350006,  36.39808 ,  38.585712,  81.54733 ,  36.545185,\n",
       "        36.812992,  71.320625,  38.59133 ,  34.578987,  34.22856 ,\n",
       "        30.669676,  38.383503,  27.520584,  38.10523 ,  36.47746 ,\n",
       "        90.69661 ,  37.280773,  39.652153,  36.49171 ,  62.690407,\n",
       "        37.48001 ,  27.493147,  34.83882 ,  38.150475,  37.91924 ,\n",
       "        38.649918,  36.806263,  38.122124,  38.63643 ,  34.987503,\n",
       "        38.54304 ,  38.58559 ,  34.352345,  34.68059 ,  38.409283,\n",
       "        27.211773,  39.226173,  36.36521 ,  34.60476 ,  36.09768 ,\n",
       "        37.850525,  39.01769 ,  38.383133,  81.14679 ,  71.17894 ,\n",
       "        51.486794,  26.875301,  36.03495 , 124.58435 ,  38.810318,\n",
       "        38.40561 ,  39.311787,  36.106342,  39.63887 ,  36.57995 ,\n",
       "        50.45343 ,  36.00588 ,  34.795124,  27.213577,  36.606293,\n",
       "        34.531853,  38.535877,  34.78034 ,  32.464977,  34.621765,\n",
       "        26.840054,  34.80649 ,  38.626347,  34.810955,  34.71876 ,\n",
       "        36.15675 ,  36.42902 ,  34.639565,  32.20144 ,  38.515644,\n",
       "        27.46699 ,  27.443163,  36.24346 ,  36.248314,  59.74045 ,\n",
       "        61.56987 ,  34.97117 ,  38.826904,  34.4147  ,  38.68581 ,\n",
       "        37.119957,  39.049404,  20.741888,  34.095013,  37.86639 ,\n",
       "        10.052136,  38.982807,  38.13969 ,  38.320293,  26.99939 ,\n",
       "        38.607433,  95.479774,  39.43054 ,  38.42482 ,  61.470013,\n",
       "        50.568966,  19.72815 ,  36.221302,  38.41181 ,  10.090717,\n",
       "        30.760742,  36.280815,  36.722378,  38.178265,  38.410526,\n",
       "        37.416367,  49.713604], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.mean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 137, 30])\n",
      "torch.Size([35, 137, 30])\n",
      "torch.Size([35, 137, 30])\n",
      "torch.Size([35, 137, 30])\n",
      "torch.Size([35, 137, 30])\n",
      "torch.Size([35, 137, 30])\n",
      "torch.Size([35, 137, 30])\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import torch.distributions as dist\n",
    "preds = []\n",
    "trues = []\n",
    "# mases = []\n",
    "\n",
    "# Initialize accumulators for errors\n",
    "total_mae = 0\n",
    "total_mse = 0\n",
    "n_samples = 0\n",
    "itr = 0\n",
    "\n",
    "cfg.seq_len = 168\n",
    "cfg.pred_len = 24\n",
    "model.eval()\n",
    "# import pdb; pdb.set_trace()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        #enumerate(test_loader): #tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "        data = test_data[i]\n",
    "        seq_x, text_embedding, observed_mask = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        seq_x = seq_x.float().to(device)\n",
    "        batch_x = seq_x[:, :cfg.seq_len].unsqueeze(-1) # 137, 168, 1\n",
    "        batch_y = seq_x[:,cfg.seq_len:cfg.seq_len+cfg.pred_len]\n",
    "        trues.append(batch_y.cpu().numpy())\n",
    "\n",
    "                        \n",
    "        outputs, _ = model(batch_x, 0, None, None, None) #+ model(seq_seasonal, ii) + model(seq_resid, ii)\n",
    "\n",
    "        mu, sigma, nu = outputs[0], outputs[1], outputs[2]\n",
    "        # Create the Student's t-distribution with the predicted parameters\n",
    "        student_t = dist.StudentT(df=nu, loc=mu, scale=sigma)\n",
    "\n",
    "        # Generate 30 samples for each prediction\n",
    "        num_samples = 35\n",
    "        probabilistic_forecasts = student_t.rsample((num_samples,))\n",
    "\n",
    "        # The shape of probabilistic_forecasts will be (num_samples, batch_size, pred_length)\n",
    "        print(probabilistic_forecasts.shape)\n",
    "        preds.append(probabilistic_forecasts.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.81706506, -0.81706506, -0.81706506, ..., -0.81706506,\n",
       "        -0.81706506, -0.81706506],\n",
       "       [-0.72572196, -0.72572196, -0.72572196, ..., -0.72572196,\n",
       "        -0.72572196, -0.72572196],\n",
       "       [-0.71024656, -0.71024656, -0.71024656, ..., -0.71024656,\n",
       "        -0.71024656, -0.71024656],\n",
       "       ...,\n",
       "       [-0.7138923 , -0.7138923 , -0.7138923 , ..., -0.7138923 ,\n",
       "        -0.7138923 , -0.7138923 ],\n",
       "       [-0.8102401 , -0.8102401 , -0.8102401 , ..., -0.8102401 ,\n",
       "        -0.8102401 , -0.8102401 ],\n",
       "       [-0.71037203, -0.71037203, -0.71037203, ..., -0.71037203,\n",
       "        -0.71037203, -0.71037203]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trues[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.9282118 , -0.6960738 , -0.7322746 , ..., -0.77908736,\n",
       "         -0.6711371 , -0.43116292],\n",
       "        [-0.7405034 , -0.71399134, -0.7741934 , ..., -0.65870476,\n",
       "         -0.62544435, -0.6820428 ],\n",
       "        [-0.5781708 , -0.6374622 , -0.6082664 , ..., -0.8387711 ,\n",
       "         -0.840068  , -0.8321725 ],\n",
       "        ...,\n",
       "        [-0.58394253, -0.5504097 , -0.67426914, ..., -0.775542  ,\n",
       "         -0.97133744, -0.2898679 ],\n",
       "        [-0.834128  , -0.8469678 , -0.8209683 , ..., -0.7103567 ,\n",
       "         -0.9341038 , -0.16032001],\n",
       "        [-0.6759638 , -0.79649895, -0.84350353, ..., -0.8641352 ,\n",
       "         -0.72463834, -0.34910887]],\n",
       "\n",
       "       [[-0.8016211 , -0.79438305, -0.70365155, ..., -0.75734043,\n",
       "         -0.6961845 , -0.4723705 ],\n",
       "        [-0.7371537 , -0.6779119 , -0.7249288 , ..., -0.5984942 ,\n",
       "         -0.742493  , -0.36965835],\n",
       "        [-0.7520069 , -0.6641639 , -0.6075448 , ..., -0.3887201 ,\n",
       "         -0.27037713, -0.4239577 ],\n",
       "        ...,\n",
       "        [-0.797414  , -0.7909659 , -0.66514206, ..., -0.7139265 ,\n",
       "         -0.6950587 , -0.74784815],\n",
       "        [-0.8196489 , -0.7199267 , -0.8486047 , ..., -0.77951646,\n",
       "         -0.8405953 , -0.61836404],\n",
       "        [-0.61860704, -0.64992374, -0.6276516 , ..., -0.6762166 ,\n",
       "         -0.9234942 , -0.58577985]],\n",
       "\n",
       "       [[-0.7795405 , -0.7133674 , -0.7625328 , ..., -0.7735009 ,\n",
       "         -0.666387  ,  0.20428482],\n",
       "        [-0.68899024, -0.67399526, -0.74774575, ..., -0.7013037 ,\n",
       "         -0.6472374 , -0.6314349 ],\n",
       "        [-0.7048933 , -0.5265745 , -0.80969316, ..., -0.6387833 ,\n",
       "         -0.7838483 , -0.4557219 ],\n",
       "        ...,\n",
       "        [-0.7230603 , -0.59067655, -0.736187  , ..., -0.7774145 ,\n",
       "         -0.46529922, -0.80881363],\n",
       "        [-0.866058  , -0.7369538 , -0.86723053, ..., -0.78007287,\n",
       "         -0.65880245, -0.617358  ],\n",
       "        [-0.68119067, -0.6659524 , -0.65704805, ..., -0.63983846,\n",
       "         -0.52417535, -1.2455177 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.7228134 , -0.7159112 , -0.7447488 , ..., -0.71745026,\n",
       "         -0.537914  , -0.5011946 ],\n",
       "        [-0.65025824, -0.64637846, -0.7155037 , ..., -0.69654095,\n",
       "         -0.72921866, -0.57400316],\n",
       "        [-0.5562017 , -0.5859232 , -0.64922935, ..., -0.63959295,\n",
       "         -0.71481   , -0.49811417],\n",
       "        ...,\n",
       "        [-0.35902992, -0.6363452 , -0.6726801 , ..., -0.6817771 ,\n",
       "         -0.66723984, -0.98975194],\n",
       "        [-0.77917707, -0.7744055 , -0.8236726 , ..., -0.91871   ,\n",
       "         -0.72965163, -0.3248161 ],\n",
       "        [-0.68068457, -0.37678188, -0.5872546 , ..., -0.6449575 ,\n",
       "         -0.59404296, -0.65023327]],\n",
       "\n",
       "       [[-0.8595594 , -0.86548036, -0.8959764 , ..., -0.77585185,\n",
       "         -0.662522  , -0.4897637 ],\n",
       "        [-0.6482965 , -0.65578306, -0.7397013 , ..., -0.70917267,\n",
       "         -0.7329439 , -0.7025447 ],\n",
       "        [-0.57578796, -0.71863294, -0.45859808, ..., -0.67921096,\n",
       "         -0.87372154, -0.3728114 ],\n",
       "        ...,\n",
       "        [-0.6895264 , -0.418204  , -0.53148437, ..., -0.59723324,\n",
       "         -0.5621217 , -0.5778725 ],\n",
       "        [-0.7530609 , -1.0254279 , -0.86497474, ..., -0.6376369 ,\n",
       "         -0.70474356, -0.62311184],\n",
       "        [-0.6861178 , -0.6235602 , -1.0781114 , ..., -0.8007274 ,\n",
       "         -0.68445575, -0.48782498]],\n",
       "\n",
       "       [[-0.86117226, -0.7753264 , -0.77879125, ..., -0.77006584,\n",
       "         -0.61060774, -0.4800853 ],\n",
       "        [-0.688009  , -0.63690174, -0.61178815, ..., -0.64305645,\n",
       "         -0.6679674 , -0.65125203],\n",
       "        [-0.1943874 , -0.6916484 , -0.45258513, ..., -0.61399907,\n",
       "         -0.593348  , -0.6225293 ],\n",
       "        ...,\n",
       "        [-0.56720746, -0.7161074 , -0.69523704, ..., -0.68808925,\n",
       "         -0.6425661 , -0.655987  ],\n",
       "        [-0.7562563 , -0.66849214, -0.8282203 , ..., -0.79570544,\n",
       "         -0.6406221 , -0.40552008],\n",
       "        [-0.75013614, -0.63866884, -0.6851033 , ..., -0.68136346,\n",
       "         -0.7840283 , -0.44137892]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7, 35, 137, 30), (7, 137, 24))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(preds).shape, np.array(trues).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data = np.array(trues)\n",
    "synthetic_data = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = synthetic_data[:,:,:, :gt_data.shape[2]]\n",
    "target_mask = np.ones_like(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic_data = np.swapaxes(synthetic_data, -1, -2)\n",
    "# gt_data = np.swapaxes(gt_data, -1, -2)\n",
    "# synthetic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.imputation_metrics import mse_withmask, mae_withmask, calc_quantile_CRPS, calc_quantile_CRPS_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98885767083419"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_quantile_CRPS_sum(torch.Tensor(gt_data),torch.Tensor(synthetic_data),torch.Tensor(target_mask),mean_scaler=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic_data = np.array(synthetic_data).reshape(synthetic_data.shape[0],-1,synthetic_data.shape[2],synthetic_data.shape[3])\n",
    "# gt_data = np.array(gt_data).reshape(gt_data.shape[0],gt_data.shape[2], -1)\n",
    "# target_mask = np.ones_like(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7, 137, 24), (7, 35, 137, 24))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unormzalized_gt_data = []\n",
    "for g in gt_data:\n",
    "    unormzalized_gt_data.append(np.transpose(np.transpose(g)*test_data.std_data+test_data.mean_data))\n",
    "unormzalized_gt_data = np.array(unormzalized_gt_data)\n",
    "unormalized_synthetic_data = []\n",
    "for i in range(len(synthetic_data)):\n",
    "    for j in range(len(synthetic_data[i])):\n",
    "        s = synthetic_data[i][j]\n",
    "        unormalized_synthetic_data.append(np.transpose(np.transpose(s)*test_data.std_data+test_data.mean_data))\n",
    "unormalized_synthetic_data = np.array(unormalized_synthetic_data).reshape(synthetic_data.shape[0],-1,synthetic_data.shape[2],synthetic_data.shape[3])\n",
    "unormzalized_gt_data.shape,unormalized_synthetic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 24, 137)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unormzalized_gt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 35, 24, 137)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unormalized_synthetic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 24, 137)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "unormalized_synthetic_data = np.swapaxes(unormalized_synthetic_data, -1, -2)\n",
    "unormzalized_gt_data = np.swapaxes(unormzalized_gt_data, -1, -2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mask = np.ones_like(unormzalized_gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46642715052554484"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data),torch.Tensor(target_mask),mean_scaler=0,scaler=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
