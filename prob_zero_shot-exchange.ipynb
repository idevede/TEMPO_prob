{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider.data_factory import data_provider\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual, vali, test\n",
    "from torch.utils.data import Subset\n",
    "from tqdm import tqdm\n",
    "from models.PatchTST import PatchTST\n",
    "from models.GPT4TS import GPT4TS\n",
    "from models.DLinear import DLinear\n",
    "from models.TEMPO import TEMPO\n",
    "# from models.T5 import T54TS\n",
    "from models.ETSformer import ETSformer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from numpy.random import choice\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from numpy.random import choice\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init_config(config_path=None):\n",
    "    config = OmegaConf.load(config_path)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to ./configs/custom_dataset.yml\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Define the configuration dictionary\n",
    "config = {\n",
    "    \"datasets\": {\n",
    "        \"Exchange\": {\n",
    "            \"root_path\": \"/u/dcao1/workspace/Generative-TS-train_all/csdi_data/exchange/\",\n",
    "            \"data_path\": \"train\",\n",
    "            \"data_name\": \"Exchange\",\n",
    "            \"data\": \"exchange\",\n",
    "            \"lradj\": \"type4\",\n",
    "            \"features\": \"M\",\n",
    "            \"target\": \"400001\",\n",
    "            \"embed\": \"timeF\",\n",
    "            \"freq\": 0,\n",
    "            \"percent\": 100\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create an OmegaConf object from the dictionary\n",
    "cfg = OmegaConf.create(config)\n",
    "\n",
    "# Save the configuration to a YAML file\n",
    "with open(\"./configs/custom_dataset.yml\", \"w\") as f:\n",
    "    OmegaConf.save(cfg, f)\n",
    "\n",
    "print(\"Configuration saved to ./configs/custom_dataset.yml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration written to config.yml\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"description\": \"TEMPO\",\n",
    "    \"checkpoints\": \"checkpoints/lora_revin_5domain_checkpoints_1/\",\n",
    "    \"task_name\": \"long_term_forecast\",\n",
    "    \"prompt\": 1,\n",
    "    \"num_nodes\": 1,\n",
    "    \"seq_len\": 168,\n",
    "    \"pred_len\": 30,\n",
    "    \"label_len\": 30,\n",
    "    \"decay_fac\": 0.5,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 256,\n",
    "    \"num_workers\": 0,\n",
    "    \"train_epochs\": 10,\n",
    "    \"lradj\": \"type3\",\n",
    "    \"patience\": 5,\n",
    "    \"gpt_layers\": 6,\n",
    "    \"is_gpt\": 1,\n",
    "    \"e_layers\": 3,\n",
    "    \"d_model\": 768,\n",
    "    \"n_heads\": 4,\n",
    "    \"d_ff\": 768,\n",
    "    \"dropout\": 0.3,\n",
    "    \"enc_in\": 7,\n",
    "    \"c_out\": 1,\n",
    "    \"patch_size\": 16,\n",
    "    \"kernel_size\": 25,\n",
    "    \"loss_func\": \"mse\",\n",
    "    \"pretrain\": 1,\n",
    "    \"freeze\": 1,\n",
    "    \"model\": \"TEMPO\",\n",
    "    \"stride\": 8,\n",
    "    \"max_len\": -1,\n",
    "    \"hid_dim\": 16,\n",
    "    \"tmax\": 20,\n",
    "    \"itr\": 3,\n",
    "    \"cos\": 1,\n",
    "    \"equal\": 1,\n",
    "    \"pool\": False,\n",
    "    \"no_stl_loss\": False,\n",
    "    \"stl_weight\": 0.001,\n",
    "    \"config_path\": \"./configs/custom_dataset.yml\",\n",
    "    \"datasets\": \"ETTm1,ETTh1,ETTm2,electricity,traffic,weather\",\n",
    "    \"target_data\": \"Exchange\",\n",
    "    \"use_token\": 0,\n",
    "    \"electri_multiplier\": 1,\n",
    "    \"traffic_multiplier\": 1,\n",
    "    \"embed\": \"timeF\",\n",
    "    \"percent\": 100,\n",
    "    # \"model_id\": 'prob_TEMPO_6_prompt_learn_168_24_100_sl336_ll168_pl24_dm768_nh4_el3_gl6_df768_ebtimeF_itr0' #\"prob_TEMPO_6_prompt_learn_168_24_100_sl336_ll30_pl30_dm768_nh4_el3_gl6_df768_ebtimeF_itr0\"\n",
    "    \"model_id\": \"prob_TEMPO_6_prompt_learn_168_30_100_sl336_ll30_pl30_dm768_nh4_el3_gl6_df768_ebtimeF_itr0\"\n",
    "}\n",
    "\n",
    "# Create an OmegaConf object from the dictionary\n",
    "cfg = OmegaConf.create(config)\n",
    "\n",
    "# Save the configuration to a YAML file\n",
    "with open(\"configs/etth2_config.yml\", \"w\") as f:\n",
    "    OmegaConf.save(cfg, f)\n",
    "\n",
    "print(\"Configuration written to config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_init_config(cfg.config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASONALITY_MAP = {\n",
    "   \"minutely\": 1440,\n",
    "   \"10_minutes\": 144,\n",
    "   \"half_hourly\": 48,\n",
    "   \"hourly\": 24,\n",
    "   \"daily\": 7,\n",
    "   \"weekly\": 1,\n",
    "   \"monthly\": 12,\n",
    "   \"quarterly\": 4,\n",
    "   \"yearly\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 308736 || all params: 82207488 || trainable%: 0.38\n"
     ]
    }
   ],
   "source": [
    "if cfg.model == 'PatchTST':\n",
    "    model = PatchTST(cfg, device)\n",
    "    model.to(device)\n",
    "elif cfg.model == 'DLinear':\n",
    "    model = DLinear(cfg, device)\n",
    "    model.to(device)\n",
    "elif cfg.model == 'TEMPO':\n",
    "    model = TEMPO(cfg, device)\n",
    "    model.to(device)\n",
    "elif cfg.model == 'T5':\n",
    "    model = T54TS(cfg, device)\n",
    "    model.to(device)\n",
    "elif 'ETSformer' in cfg.model:\n",
    "    model = ETSformer(cfg, device)\n",
    "    model.to(device)\n",
    "else:\n",
    "    model = GPT4TS(cfg, device)\n",
    "\n",
    "\n",
    "params = model.parameters()\n",
    "model_optim = torch.optim.Adam(params, lr=cfg.learning_rate)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=cfg.patience, verbose=True)\n",
    "if cfg.loss_func == 'mse':\n",
    "    criterion = nn.MSELoss()\n",
    "elif cfg.loss_func == 'smape':\n",
    "    class SMAPE(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SMAPE, self).__init__()\n",
    "        def forward(self, pred, true):\n",
    "            return torch.mean(200 * torch.abs(pred - true) / (torch.abs(pred) + torch.abs(true) + 1e-8))\n",
    "    criterion = SMAPE()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(model_optim, T_max=cfg.tmax, eta_min=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/lora_revin_5domain_checkpoints_1/prob_TEMPO_6_prompt_learn_168_30_100_sl336_ll30_pl30_dm768_nh4_el3_gl6_df768_ebtimeF_itr0/checkpoint.pth\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(cfg.checkpoints, cfg.model_id)\n",
    "best_model_path = model_path + '/checkpoint.pth'\n",
    "print(best_model_path)\n",
    "model.load_state_dict(torch.load(best_model_path,  map_location=torch.device(device)), strict=False)\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Exchange': {'root_path': '/u/dcao1/workspace/Generative-TS-train_all/csdi_data/exchange/', 'data_path': 'train', 'data_name': 'Exchange', 'data': 'exchange', 'lradj': 'type4', 'features': 'M', 'target': '400001', 'embed': 'timeF', 'freq': 0, 'percent': 100}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['datasets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.enc_in = 8\n",
      "self.data_x = (5, 8)\n",
      "test 5\n"
     ]
    }
   ],
   "source": [
    "cfg.data = config['datasets'][cfg.target_data].data\n",
    "cfg.root_path = config['datasets'][cfg.target_data].root_path\n",
    "cfg.data_path = config['datasets'][cfg.target_data].data_path\n",
    "cfg.data_name = config['datasets'][cfg.target_data].data_name\n",
    "cfg.features = config['datasets'][cfg.target_data].features\n",
    "cfg.freq = config['datasets'][cfg.target_data].freq\n",
    "cfg.target = config['datasets'][cfg.target_data].target\n",
    "cfg.embed = config['datasets'][cfg.target_data].embed\n",
    "cfg.percent = config['datasets'][cfg.target_data].percent\n",
    "cfg.lradj = config['datasets'][cfg.target_data].lradj\n",
    "if cfg.freq == 0:\n",
    "    cfg.freq = 'h'\n",
    "cfg.pred_len = 30 \n",
    "cfg.seq_len = 90+cfg.pred_len #168 + 24\n",
    "\n",
    "test_data, test_loader = data_provider(cfg, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 8, 30])\n",
      "torch.Size([35, 8, 30])\n",
      "torch.Size([35, 8, 30])\n",
      "torch.Size([35, 8, 30])\n",
      "torch.Size([35, 8, 30])\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import torch.distributions as dist\n",
    "preds = []\n",
    "trues = []\n",
    "history = []\n",
    "# mases = []\n",
    "\n",
    "# Initialize accumulators for errors\n",
    "total_mae = 0\n",
    "total_mse = 0\n",
    "n_samples = 0\n",
    "itr = 0\n",
    "\n",
    "cfg.seq_len = cfg.seq_len - cfg.pred_len\n",
    "# cfg.pred_len = 24\n",
    "model.eval()\n",
    "# import pdb; pdb.set_trace()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        #enumerate(test_loader): #tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "        data = test_data[i]\n",
    "        seq_x, text_embedding, observed_mask = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        seq_x = seq_x.float().to(device)\n",
    "        # print(seq_x.shape)\n",
    "        batch_x = seq_x[:, :cfg.seq_len].unsqueeze(-1) # 137, 168, 1\n",
    "        history.append(batch_x.cpu().numpy())\n",
    "        if batch_x.shape[1] < 168:\n",
    "            # zeros_padding = torch.zeros((batch_x.shape[0], 168-batch_x.shape[1], batch_x.shape[2])).to(device)\n",
    "            # batch_x = torch.cat([zeros_padding, batch_x], dim=1)\n",
    "            n = 168 - batch_x.shape[1]\n",
    "            # Select the last n elements along the second dimension\n",
    "            last_elements = batch_x[:, -n:, :]\n",
    "            # print(last_elements.shape)\n",
    "            # Concatenate these elements to the beginning of batch_x\n",
    "            batch_x = torch.cat([last_elements, batch_x], dim=1)\n",
    "            # print(batch_x.shape)\n",
    "        batch_y = seq_x[:,cfg.seq_len:cfg.seq_len+cfg.pred_len]\n",
    "        trues.append(batch_y.cpu().numpy())\n",
    "        \n",
    "                        \n",
    "        outputs, _ = model(batch_x, 0, None, None, None) #+ model(seq_seasonal, ii) + model(seq_resid, ii)\n",
    "\n",
    "        mu, sigma, nu = outputs[0], outputs[1], outputs[2]\n",
    "        # Create the Student's t-distribution with the predicted parameters\n",
    "        student_t = dist.StudentT(df=nu, loc=mu, scale=sigma)\n",
    "\n",
    "        # Generate 30 samples for each prediction\n",
    "        num_samples = 35\n",
    "        probabilistic_forecasts = student_t.rsample((num_samples,))\n",
    "\n",
    "        # The shape of probabilistic_forecasts will be (num_samples, batch_size, pred_length)\n",
    "        print(probabilistic_forecasts.shape)\n",
    "        preds.append(probabilistic_forecasts.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.05285037e+00,  1.04995847e+00,  1.05012047e+00, ...,\n",
       "          1.09085929e+00,  1.05333257e+00,  1.07703257e+00],\n",
       "        [ 1.59139740e+00,  1.59005404e+00,  1.59381592e+00, ...,\n",
       "          1.52979231e+00,  1.61871552e+00,  1.49598503e+00],\n",
       "        [ 1.02235246e+00,  1.01095641e+00,  9.80429173e-01, ...,\n",
       "          1.05954266e+00,  1.00503647e+00,  1.00508928e+00],\n",
       "        ...,\n",
       "        [ 1.27800480e-02,  1.40290717e-02,  1.28641818e-02, ...,\n",
       "          1.26518281e-02,  1.50356237e-02,  7.97123462e-03],\n",
       "        [ 8.20384085e-01,  7.92123079e-01,  7.86972642e-01, ...,\n",
       "          8.41658831e-01,  8.02961111e-01,  7.95226574e-01],\n",
       "        [ 7.78243184e-01,  8.00467014e-01,  8.05271566e-01, ...,\n",
       "          7.16349721e-01,  7.40217566e-01,  7.86302924e-01]],\n",
       "\n",
       "       [[ 9.92144406e-01,  1.03753996e+00,  1.05467677e+00, ...,\n",
       "          1.09787655e+00,  1.05419433e+00,  1.08841836e+00],\n",
       "        [ 1.58861089e+00,  1.57728899e+00,  1.58153009e+00, ...,\n",
       "          1.62326288e+00,  1.58653891e+00,  1.49849594e+00],\n",
       "        [ 1.01624596e+00,  1.00012124e+00,  9.98944819e-01, ...,\n",
       "          1.02204704e+00,  1.12678623e+00,  9.93433893e-01],\n",
       "        ...,\n",
       "        [ 9.40816384e-03,  7.27345794e-03,  1.34642981e-02, ...,\n",
       "          1.56124914e-02,  2.24850979e-02,  1.07751638e-02],\n",
       "        [ 8.21658075e-01,  7.78139651e-01,  7.82027841e-01, ...,\n",
       "          7.22636759e-01,  9.37693059e-01,  8.56869757e-01],\n",
       "        [ 7.92199731e-01,  8.04217756e-01,  7.73713350e-01, ...,\n",
       "          7.25171506e-01,  8.13747227e-01,  7.27657080e-01]],\n",
       "\n",
       "       [[ 1.04313433e+00,  1.04180181e+00,  1.02177238e+00, ...,\n",
       "          1.09580100e+00,  1.07401645e+00,  9.99732316e-01],\n",
       "        [ 1.60680103e+00,  1.59113061e+00,  1.70005465e+00, ...,\n",
       "          1.57990575e+00,  1.58153212e+00,  1.50274920e+00],\n",
       "        [ 1.01600266e+00,  9.62584138e-01,  1.09119952e+00, ...,\n",
       "          1.30417037e+00,  1.01544178e+00,  1.00631452e+00],\n",
       "        ...,\n",
       "        [ 1.26617085e-02,  1.22246677e-02,  1.21693537e-02, ...,\n",
       "         -1.54096819e-03,  1.93892922e-02,  1.00493515e-02],\n",
       "        [ 8.15710187e-01,  8.33745539e-01,  8.27872932e-01, ...,\n",
       "          9.88846898e-01,  7.71328211e-01,  8.47639561e-01],\n",
       "        [ 8.14470351e-01,  8.53021860e-01,  7.88242757e-01, ...,\n",
       "          6.39625788e-01,  7.92138278e-01,  8.24862003e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.04255390e+00,  1.05282259e+00,  1.05293620e+00, ...,\n",
       "          1.10334074e+00,  1.04987824e+00,  1.07063270e+00],\n",
       "        [ 1.58538938e+00,  1.56339884e+00,  1.60794353e+00, ...,\n",
       "          1.60982800e+00,  1.49642277e+00,  1.53969669e+00],\n",
       "        [ 1.00306082e+00,  9.91731405e-01,  1.00681365e+00, ...,\n",
       "          1.01063609e+00,  1.03940129e+00,  1.15145576e+00],\n",
       "        ...,\n",
       "        [ 1.10364780e-02,  5.79229090e-03,  1.43558308e-02, ...,\n",
       "          2.25118138e-02,  1.54239032e-02,  1.10622989e-02],\n",
       "        [ 8.26797843e-01,  8.03106964e-01,  8.22750807e-01, ...,\n",
       "          8.15645814e-01,  8.13936472e-01,  8.35140765e-01],\n",
       "        [ 8.18861485e-01,  6.90089464e-01,  8.43073130e-01, ...,\n",
       "          7.42128849e-01,  8.86286795e-01,  7.94029415e-01]],\n",
       "\n",
       "       [[ 1.04175150e+00,  1.02078485e+00,  1.02938581e+00, ...,\n",
       "          1.16272247e+00,  1.12636280e+00,  9.34850454e-01],\n",
       "        [ 1.58927703e+00,  1.59022188e+00,  1.56072104e+00, ...,\n",
       "          1.56156027e+00,  8.11156988e-01,  1.63426077e+00],\n",
       "        [ 1.01798427e+00,  1.01532257e+00,  9.81912374e-01, ...,\n",
       "          9.60527420e-01,  1.00584233e+00,  9.49975014e-01],\n",
       "        ...,\n",
       "        [ 6.98089087e-03, -1.02501363e-03,  5.80437062e-03, ...,\n",
       "          1.64022129e-02,  2.32372023e-02,  7.16242008e-04],\n",
       "        [ 8.21945250e-01,  8.16584885e-01,  8.58040571e-01, ...,\n",
       "          8.86263728e-01,  8.42576563e-01,  8.09601426e-01],\n",
       "        [ 7.94317305e-01,  8.02518725e-01,  8.00035655e-01, ...,\n",
       "          7.96233177e-01,  8.86347413e-01,  8.30717385e-01]],\n",
       "\n",
       "       [[ 1.04653943e+00,  1.03675139e+00,  9.67631459e-01, ...,\n",
       "          1.03492939e+00,  1.04661322e+00,  1.03971362e+00],\n",
       "        [ 1.58317232e+00,  1.54435337e+00,  1.61180699e+00, ...,\n",
       "          1.58736980e+00,  1.52494419e+00,  1.55089438e+00],\n",
       "        [ 9.89062965e-01,  1.00940943e+00,  1.04747009e+00, ...,\n",
       "          1.05035174e+00,  1.04630947e+00,  9.29921746e-01],\n",
       "        ...,\n",
       "        [ 9.19423439e-03,  1.27312504e-02,  1.00844037e-02, ...,\n",
       "         -4.51135449e-03,  1.86794028e-02,  7.09862076e-03],\n",
       "        [ 8.04399848e-01,  8.16797316e-01,  8.34413350e-01, ...,\n",
       "          5.00315428e-01,  8.27014208e-01,  8.74850214e-01],\n",
       "        [ 8.44343543e-01,  8.03483248e-01,  7.99068987e-01, ...,\n",
       "          7.67786086e-01,  8.25612426e-01,  9.79530692e-01]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 35, 8, 30), (5, 8, 30))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(preds).shape, np.array(trues).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data = np.array(trues)\n",
    "synthetic_data = np.array(preds)\n",
    "history_data = np.array(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = synthetic_data[:,:,:, :gt_data.shape[2]]\n",
    "target_mask = np.ones_like(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic_data = np.swapaxes(synthetic_data, -1, -2)\n",
    "# gt_data = np.swapaxes(gt_data, -1, -2)\n",
    "# synthetic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.imputation_metrics import mse_withmask, mae_withmask, calc_quantile_CRPS, calc_quantile_CRPS_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015199105990560432"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_quantile_CRPS_sum(torch.Tensor(gt_data),torch.Tensor(synthetic_data),torch.Tensor(target_mask),mean_scaler=0,scaler=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic_data = np.array(synthetic_data).reshape(synthetic_data.shape[0],-1,synthetic_data.shape[2],synthetic_data.shape[3])\n",
    "# gt_data = np.array(gt_data).reshape(gt_data.shape[0],gt_data.shape[2], -1)\n",
    "# target_mask = np.ones_like(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unormzalized_his_data = []\n",
    "for g in history_data:\n",
    "    unormzalized_his_data.append(np.transpose(np.transpose(g)*test_data.std_data+test_data.mean_data))\n",
    "unormzalized_his_data = np.array(unormzalized_his_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 8, 30), (5, 35, 8, 30))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unormzalized_gt_data = []\n",
    "for g in gt_data:\n",
    "    unormzalized_gt_data.append(np.transpose(np.transpose(g)*test_data.std_data+test_data.mean_data))\n",
    "unormzalized_gt_data = np.array(unormzalized_gt_data)\n",
    "unormalized_synthetic_data = []\n",
    "for i in range(len(synthetic_data)):\n",
    "    for j in range(len(synthetic_data[i])):\n",
    "        s = synthetic_data[i][j]\n",
    "        unormalized_synthetic_data.append(np.transpose(np.transpose(s)*test_data.std_data+test_data.mean_data))\n",
    "unormalized_synthetic_data = np.array(unormalized_synthetic_data).reshape(synthetic_data.shape[0],-1,synthetic_data.shape[2],synthetic_data.shape[3])\n",
    "unormzalized_gt_data.shape,unormalized_synthetic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 30)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unormzalized_gt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 35, 8, 30)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unormalized_synthetic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 30)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unormalized_synthetic_data = np.swapaxes(unormalized_synthetic_data, -1, -2)\n",
    "unormzalized_gt_data = np.swapaxes(unormzalized_gt_data, -1, -2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mask = np.ones_like(unormzalized_gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027888950548673932"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data),torch.Tensor(target_mask),mean_scaler=0,scaler=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all:   CRPS_sum:\n",
      "0.027888950548673932\n",
      "all: CRPS_sum:\n",
      "Mean CRPS_sum: 0.03004905424619976\n",
      "Standard Deviation CRPS_sum: 0.0007420568835543681\n"
     ]
    }
   ],
   "source": [
    "print(\"all:   CRPS_sum:\")\n",
    "print(calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data),torch.Tensor(target_mask),mean_scaler=0,scaler=1))\n",
    "print(\"all: CRPS_sum:\")\n",
    "# import pdb; pdb.set_trace()\n",
    "CRPS_sum_1 = calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data[:,:10]),torch.Tensor(target_mask),mean_scaler=0,scaler=1)\n",
    "CRPS_sum_2 = calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data[:,10:20]),torch.Tensor(target_mask),mean_scaler=0,scaler=1)\n",
    "CRPS_sum_3 = calc_quantile_CRPS_sum(torch.Tensor(unormzalized_gt_data),torch.Tensor(unormalized_synthetic_data[:,20:30]),torch.Tensor(target_mask),mean_scaler=0,scaler=1)\n",
    "\n",
    "CRPS_sum_mean = np.mean([CRPS_sum_1, CRPS_sum_2, CRPS_sum_3])\n",
    "CRPS_sum_std = np.std([CRPS_sum_1, CRPS_sum_2, CRPS_sum_3])\n",
    "print(\"Mean CRPS_sum:\", CRPS_sum_mean)\n",
    "print(\"Standard Deviation CRPS_sum:\", CRPS_sum_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_q = np.quantile(synthetic_data,0.05,axis=1)\n",
    "high_q = np.quantile(synthetic_data,0.95,axis=1)\n",
    "mid_q = np.quantile(synthetic_data,0.5,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 8, 90, 1), (5, 8, 30))"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_data.shape, gt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 120)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_data = np.concatenate([history_data.squeeze(), gt_data], axis=2)\n",
    "traj_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.pred_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (5, 8, 120)\n",
      "1 (5, 8, 120)\n",
      "2 (5, 8, 120)\n",
      "3 (5, 8, 120)\n",
      "4 (5, 8, 120)\n",
      "5 (5, 8, 120)\n",
      "6 (5, 8, 120)\n",
      "7 (5, 8, 120)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "i = 0\n",
    "#3000\n",
    "seq_len = 120 #92\n",
    "feat_dim = synthetic_data.shape[2]\n",
    "feat_dim = 8\n",
    "fig, axes = plt.subplots(nrows=feat_dim, ncols=1, figsize=(10, 20))\n",
    "for feat_idx in range(feat_dim):\n",
    "    # df_x = pd.DataFrame({\"x\": np.arange(0, seq_len), \"val\": gt_data[i, feat_idx, :],\n",
    "    #                      \"y\": (1-target_mask)[i, feat_idx, :]})\n",
    "    # df_x = df_x[df_x.y!=0]\n",
    "    print(feat_idx, traj_data.shape)\n",
    "    df_o = pd.DataFrame({\"x\": np.arange(0, seq_len), \"val\": traj_data[i, feat_idx, :]})\n",
    "                        # \"y\": target_mask[i, feat_idx, :]})\n",
    "    # df_o = df_o[df_o.y!=0]\n",
    "    axes[feat_idx].plot(df_o.x, df_o.val, color='b',  linestyle='solid', label='label')\n",
    "    # axes[feat_idx].plot(df_x.x, df_x.val, color='r', marker='x', linestyle='None')\n",
    "    axes[feat_idx].plot(range(seq_len-cfg.pred_len, seq_len), mid_q[i, feat_idx, -cfg.pred_len:], color='g', linestyle='solid', label='Diffusion-TS')\n",
    "    axes[feat_idx].fill_between(range(seq_len-cfg.pred_len, seq_len), low_q[i, feat_idx,-cfg.pred_len:],high_q[i,feat_idx, -cfg.pred_len:], color='g', alpha = 0.3)\n",
    "    plt.setp(axes[feat_idx], ylabel='value')\n",
    "    if feat_idx == feat_dim-1:\n",
    "        plt.setp(axes[-1], xlabel='time')\n",
    "    # plt.show()\n",
    "    # axes[feat_idx].set_ylim(-3, 3)\n",
    "plt.legend()\n",
    "plt.savefig('traffic_1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.WIS import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = np.swapaxes(unormalized_synthetic_data, -1, -2)\n",
    "\n",
    "labels = np.swapaxes(unormzalized_gt_data, -1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_q = np.quantile(synthetic_data,0.05,axis=1)\n",
    "high_q = np.quantile(synthetic_data,0.95,axis=1)\n",
    "mid_q = np.quantile(synthetic_data,0.5,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 30) (40, 30) (40, 30)\n"
     ]
    }
   ],
   "source": [
    "high_q_reshape = np.reshape(high_q,newshape=(-1,high_q.shape[-1]))\n",
    "low_q_reshape = np.reshape(low_q,newshape=(-1,low_q.shape[-1]))\n",
    "gt_data_reshape = np.reshape(labels,newshape=(-1,labels.shape[-1]))\n",
    "print(high_q_reshape.shape,low_q_reshape.shape,gt_data_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05 # to be set by competition hosts\n",
    "if not(alpha > 0 and alpha <= 1):\n",
    "    raise ParticipantVisibleError(f'alpha should be (0,1]. Found {alpha}')\n",
    "\n",
    "MWIS,coverage = score(gt_data_reshape,high_q_reshape,low_q_reshape,alpha)\n",
    "\n",
    "if not(coverage >= (1-alpha)):\n",
    "    raise ParticipantVisibleError(f'Coverage was below {(1-alpha)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.32336958353128276, 27.55)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MWIS,coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
